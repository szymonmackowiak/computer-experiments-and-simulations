{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ocena klasyfikatorów binarnych\n",
    "\n",
    "### Wprowadzenie \n",
    "Wynikiem pracy klasyfikatorów binarnych jest zwrócenie w odpowiedzi na zadany wektor cech jednej z dwóch wartości (np. prawda-fałsz, 0-1 itd.). Porównując odpowiedź klasyfikatora z rzeczywistą etykietą testowego zestawu cech, możemy uzyskać jedną z czterech możliwości:\n",
    "- algorytm poprawnie przewidział wartość prawdziwą (true positive hit / TP),\n",
    "- algorytm poprawnie przewidział wartość fałszywą (true negative hit / TN),\n",
    "- algorytm niepoprawnie przewidział wartość prawdziwą (false positive / FP / false alarm / Type I error),\n",
    "- algorytm niepoprawnie przewidział wartość fałszywą (false negative / FN / with miss / Type II error).\n",
    "Porządaną sytuacją jest maksymalizacja wyników dla których algorytm poprawnie przewiduje wartości prawdy i fałszu (a więc dwie pierwsze sytuacje z powyższej listy).\n",
    "\n",
    "### Stosowane miary\n",
    "\n",
    "1. Czułość i specyficzność:\n",
    "- czułość (true positive rate - TPR): prawdopodobieństwo klasyfikacji poprawnej pod warunkiem, że przypadek jest pozytywny <br>\n",
    "$TPR = \\frac{TP}{P} = \\frac{TP}{TP+FN}$\n",
    "- specyficzność (true negative rate - TNR): prawdopodobieństwo klasyfikacji poprawnej pod warunkiem, że przypadek jest negatywny <br>\n",
    "$TNR = \\frac(TN){N} = \\frac{TN}{TN+FP}$\n",
    "\n",
    "2. Fałszywe alarmy:\n",
    "- częstość fałszywych alarmów (false positive rate - FPR): prawdopodonieństwo klasyfikacji pozytywnej pod warunkiem, że przypadek jest negatywny <br>\n",
    "$FPR = \\frac{FP}{N} = \\frac{FP}{FP+TN}$\n",
    "- częśtość fałszywych odkryć (false discovery rate - FDR): jak wiele spośród klasyfikacji pozytywnych jest fałszywych <br>\n",
    "$FDR = \\frac{FP}{FP+TP}$\n",
    "\n",
    "3. Precyzja:\n",
    "- precyzja pozytywna (positive predictive value - PPV): prawdopodobieństwo, że jeżeli wynik jest pozytywny, to stan faktyczny również <br>\n",
    "$PPV = \\frac{TP}{TP+FP}$\n",
    "- precyzja negatywna (negative predictive value - NPV): prawdopodobieństwo, że jeżeli wynik jest negatywny, to stan faktyczny również <br>\n",
    "$NPV = \\frac{TN}{TN+FN}$\n",
    "\n",
    "4. Miary zbalansowane:\n",
    "- dokładność (accuracy - ACC): prawdopodobieństwo prawidłowej klasyfikacji <br>\n",
    "$ACC = \\frac{TP + FN}{P + N}$\n",
    "- $F_1$ (średnia harmoniczna z precyzji i czułości) <br>\n",
    "$F_1 = \\frac{2 \\cdot PPV \\cdot TPR}{PPV + TPR}$\n",
    "\n",
    "### Reprezentacja graficzna\n",
    "\n",
    "Tablica pomyłek - powszechnie stosowany diagram w formie dwuwymiarowej tablicy, której prostopadłe osie reprezentują klasy rzeczywiste oraz klasy przewidywane. Pozwala określić prawdopodobieństwa realizacji TP, TN, FP, FN. \n",
    "\n",
    "### Literatura:\n",
    "1. https://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/Wykład_Ocena_jakości_klasyfikacji\n",
    "2. https://pl.wikipedia.org/wiki/Tablica_pomyłek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
